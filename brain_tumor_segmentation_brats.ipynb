{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_dataset = './BraTS_2020/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n",
    "Val_dataset = './BraTS_2020/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "test_image_flair = nib.load(Training_dataset + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii').get_fdata()\n",
    "test_image_t1 = nib.load(Training_dataset + 'BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\n",
    "test_image_t1ce = nib.load(Training_dataset + 'BraTS20_Training_001/BraTS20_Training_001_t1ce.nii').get_fdata()\n",
    "test_image_t2 = nib.load(Training_dataset + 'BraTS20_Training_001/BraTS20_Training_001_t2.nii').get_fdata()\n",
    "test_mask = nib.load(Training_dataset + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 10))\n",
    "slice_w = 25\n",
    "# slice_number = test_image_flair.shape[0]//2-slice_w\n",
    "slice_number = 55\n",
    "print(slice_number)\n",
    "ax1.imshow(test_image_flair[:,:,slice_number], cmap='gray')\n",
    "ax1.set_title('Image flair')\n",
    "ax2.imshow(test_image_t1[:,:,slice_number], cmap='gray')\n",
    "ax2.set_title('Image t1')\n",
    "ax3.imshow(test_image_t1ce[:,:,slice_number], cmap='gray')\n",
    "ax3.set_title('Image t1ce')\n",
    "ax4.imshow(test_image_t2[:,:,slice_number], cmap='gray')\n",
    "ax4.set_title('Image t2')\n",
    "ax5.imshow(test_mask[:,:,slice_number])\n",
    "ax5.set_title('Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import montage\n",
    "from skimage.transform import rotate\n",
    "import numpy as np\n",
    "\n",
    "# We can skip 50:-50 slices since there is not much to see\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(montage(np.transpose(test_image_t1[..., 50:-50], (2, 0, 1))), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
    "ax1.imshow(montage(np.transpose(test_mask[..., 50:-50], (2, 0, 1))), cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight = None, size_average = True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, inputs, targets, smooth = 1):\n",
    "        inputs = F.sigmoid(inputs)\n",
    "        \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "train_dir = [i.path for i in os.scandir(Training_dataset) if i.is_dir()]\n",
    "val_dir = [j.path for j in os.scandir(Val_dataset) if j.is_dir()]\n",
    "\n",
    "def path_list_into_ids(dirList):\n",
    "    x = []\n",
    "    for i in range(0, len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/') + 1:])\n",
    "    \n",
    "    return x\n",
    "\n",
    "train_test_ids = path_list_into_ids(train_dir)\n",
    "val_ids = path_list_into_ids(val_dir)\n",
    "\n",
    "# train_test_ids, val_ids = train_test_split(train_and_test_ids, test_size = 0.15)\n",
    "train_ids, test_ids = train_test_split(train_test_ids, test_size = 0.15)\n",
    "\n",
    "print(f\"Train : {len(train_ids)} | Validation : {len(val_ids)} | Test : {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(ids, path):\n",
    "    images = np.zeros((len(ids) * 10, 240, 240), np.float32)\n",
    "    masks = np.zeros((len(ids) * 10, 240, 240), np.float32)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for id in ids:\n",
    "        t2 = nib.load(f\"{path}{id}/{id}_t2.nii\").get_fdata()\n",
    "        seg = nib.load(f\"{path}{id}/{id}_seg.nii\").get_fdata()\n",
    "        \n",
    "        for s in range(50, seg.shape[2]-50, 10):\n",
    "            images[i] = t2[:, :, s] / t2.max()\n",
    "            masks[i] = seg[:, :, s] > 0\n",
    "            i += 1\n",
    "            \n",
    "    images = np.expand_dims(images[:i], axis=1)\n",
    "    masks = np.expand_dims(masks[:i], axis=1)\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "\n",
    "train_images, train_masks = load_dataset(train_ids, Training_dataset)\n",
    "val_images, val_masks = load_dataset(val_ids, Val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape, val_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(train_images[100, 0], cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(train_masks[100, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_images).type(torch.float32), torch.from_numpy(train_masks).type(torch.float32))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(val_images).type(torch.float32), torch.from_numpy(val_masks).type(torch.float32))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_categorized_slices(image_dir, mask_dir, nii_dir, slice_index=78):\n",
    "    modalities = ['t1', 't1ce', 't2', 'flair']\n",
    "    patients = [f for f in os.listdir(nii_dir) if not f.startswith('.')]\n",
    "\n",
    "    for patient in patients:\n",
    "        patient_folder = os.path.join(nii_dir, patient)\n",
    "        for modality in modalities:\n",
    "            image_path = os.path.join(patient_folder, f\"{patient}_{modality}.nii\")\n",
    "            nii_image = nib.load(image_path)\n",
    "            image_data = nii_image.get_fdata()\n",
    "\n",
    "            # Normalize and save the image slice\n",
    "            slice_img = image_data[:, :, slice_index]\n",
    "            img_norm = (slice_img - np.min(slice_img)) / (np.max(slice_img) - np.min(slice_img))\n",
    "            img_pil = Image.fromarray(np.uint8(img_norm * 255))\n",
    "            img_pil.save(os.path.join(image_dir, f\"{patient}_{modality}.png\"))\n",
    "\n",
    "        # Process and save the mask with separate channels\n",
    "        mask_path = os.path.join(patient_folder, f\"{patient}_seg.nii\")\n",
    "        nii_mask = nib.load(mask_path)\n",
    "        mask_data = nii_mask.get_fdata()\n",
    "        slice_mask = mask_data[:, :, slice_index]\n",
    "\n",
    "        # Create a blank channel for each label\n",
    "        mask_channels = {1: np.zeros_like(slice_mask), 2: np.zeros_like(slice_mask), 4: np.zeros_like(slice_mask)}\n",
    "        for label in mask_channels:\n",
    "            mask_channels[label][slice_mask == label] = 1\n",
    "\n",
    "        # Combine channels into a single image (stacking)\n",
    "        combined_mask = np.stack((mask_channels[1], mask_channels[2], mask_channels[4]), axis=-1)\n",
    "        mask_image = Image.fromarray(np.uint8(combined_mask * 255))\n",
    "        mask_image.save(os.path.join(mask_dir, f\"{patient}_seg.png\"))\n",
    "\n",
    "save_categorized_slices('./Data/image', './Data/mask', './BraTS_2020/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
